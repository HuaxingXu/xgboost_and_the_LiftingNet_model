{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import time\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import plot,savefig\n",
    "from dataset import *\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import xgboost as xgb\n",
    "import sklearn as sk\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "import mylib as ml2\n",
    "from mylib import LiftNet, create_LiftNet, create_Standard_LiftNet, Standard_LiftNet, create_Standard_LiftNet_CWRU\n",
    "\n",
    "from plotly.graph_objs import Scatter,Layout\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#setting offilne\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set default parameters\n"
     ]
    }
   ],
   "source": [
    "#------------------------default parameters-----------------------#\n",
    "test_rate = 0.2\n",
    "epochs = 1000\n",
    "\n",
    "lr=0.015\n",
    "momentum=0.8\n",
    "\n",
    "decay=0.01\n",
    "\n",
    "validation_split=0.2\n",
    "steps_per_epoch=1\n",
    "validation_steps=1\n",
    "bunch_steps = 100\n",
    "snapshot = 500\n",
    "bunch_steps = 100\n",
    "snapshot = 500\n",
    "print('set default parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape :  (832, 1024, 2)\n",
      "label shape :  (832, 1)\n",
      "set adjustable parameters\n"
     ]
    }
   ],
   "source": [
    "#------------------------adjustable parameters-----------------------#\n",
    "model_path = ['/home/silver-bullet/newpaper/model/circle_1_to_6_in_our_data/', \n",
    "              '/home/silver-bullet/newpaper/model/circle_7_to_16_in_our_data_with_0.01_noise_data/',\n",
    "              '/home/silver-bullet/newpaper/model/model_in_CWRU_data/']\n",
    "model_head_name = ['Standard_LiftingNet_',\n",
    "                   'Standard_LiftingNet_use_expansion_data__with_',\n",
    "                   'Standard_expansion_CWRU_data_LiftingNet__with_',\n",
    "                  'Standard_LiftingNet_use_expansion_data_',\n",
    "                  'Standard_expansion_CWRU_data_LiftingNet_']\n",
    "\n",
    "data_path = ['/home/silver-bullet/newpaper/data/dataset/','/home/silver-bullet/newpaper/data/CWRUdataset']\n",
    "\n",
    "class_num = 6\n",
    "circle_num = 16\n",
    "cutsize = 256\n",
    "steps = 600\n",
    "whether_use_CWRU_data = 1\n",
    "LiftingNet_noise_scale = 2\n",
    "whether_expansion_data = 1\n",
    "expansion_data_number = 500\n",
    "noise_scales = 0.01\n",
    "if whether_use_CWRU_data==1:\n",
    "    noise_scales = LiftingNet_noise_scale\n",
    "\n",
    "#artificial_feature_method: 1 is 19 features, 2 is 9 features\n",
    "artificial_feature_method = 2\n",
    "\n",
    "pca_parameters = 27\n",
    "\n",
    "if whether_use_CWRU_data == 1:\n",
    "    cutsize = 1024\n",
    "    input_shape = (cutsize,2)\n",
    "    channel = 2\n",
    "    dataset, label = load_CWRU_data(data_path[1])\n",
    "    read_model_name = model_path[2]+model_head_name[2]+str(LiftingNet_noise_scale)+'_noise_'+str(cutsize)+'_data_the_'+str(steps)+'th_snapshot_with_'+str(steps_per_epoch)+'_steps_per_epoch.h5'\n",
    "    if LiftingNet_noise_scale == 0:\n",
    "        read_model_name = model_path[2]+model_head_name[4]+str(cutsize)+'_data_the_'+str(steps)+'th_snapshot_with_'+str(steps_per_epoch)+'_steps_per_epoch.h5'\n",
    "else:\n",
    "    cutsize = 256\n",
    "    input_shape = (640*circle_num,3)\n",
    "    channel = 3\n",
    "    dataset, label = load_dataset(data_path[0], circle_num=circle_num, cutsize=cutsize)\n",
    "    if circle_num<7:\n",
    "        read_model_name = model_path[0] + model_head_name[0]+str(circle_num)+'_data_the_'+str(steps)+'th_snapshot_with_'+str(steps_per_epoch)+'_steps_per_epoch.h5'\n",
    "    else:\n",
    "        read_model_name = model_path[1] + model_head_name[1]+str(LiftingNet_noise_scale)+'_noise_'+str(circle_num)+'_data_the_'+str(steps)+'th_snapshot_with_'+str(steps_per_epoch)+'_steps_per_epoch.h5'\n",
    "\n",
    "if circle_num==8:\n",
    "    read_model_name= model_path[1] + model_head_name[3] +  str(circle_num)+'_data_the_'+str(steps)+'th_snapshot_with_'+str(steps_per_epoch)+'_steps_per_epoch.h5'\n",
    "if circle_num==12:\n",
    "    read_model_name= model_path[1] + model_head_name[0] +  str(circle_num)+'_data_the_'+str(steps)+'th_snapshot_with_'+str(steps_per_epoch)+'_steps_per_epoch.h5'\n",
    "\n",
    "print('set adjustable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 1024, 2)\n",
      "(118, 1024, 2)\n",
      "(117, 1024, 2)\n",
      "(118, 1024, 2)\n",
      "(118, 1024, 2)\n",
      "(118, 1024, 2)\n",
      "(500, 1024, 2)\n",
      "(500, 1)\n",
      "(500, 1024, 2)\n",
      "(500, 1)\n",
      "(500, 1024, 2)\n",
      "(500, 1)\n",
      "(500, 1024, 2)\n",
      "(500, 1)\n",
      "(500, 1024, 2)\n",
      "(500, 1)\n",
      "(500, 1024, 2)\n",
      "(500, 1)\n",
      "(3000, 1024, 2)\n",
      "(3000, 1)\n",
      "data_max_abs_x.shape:  (3000, 1, 2)\n",
      "noise_data.shape:  (3000, 1024, 2)\n",
      "after expansion: \n",
      "dataset shape :  (3832, 1024, 2)\n",
      "label shape :  (3832, 1)\n",
      "data expansion\n",
      "x.shape:  (3832, 1024, 2)\n",
      "y.shape:  (3832, 1)\n",
      "x_train.shape:  (3065, 1024, 2)\n",
      "x_test.shape:  (767, 1024, 2)\n",
      "y_train.shape:  (3065, 1)\n",
      "y_test.shape:  (767, 1)\n",
      "x_train_number:  3065\n",
      "x_test_number:  767\n"
     ]
    }
   ],
   "source": [
    "#------------------------expansion data parameters-----------------------#\n",
    "\n",
    "if whether_expansion_data == 1:\n",
    "    dataset, label = expansion_and_add_noise(dataset,label,exnumber=expansion_data_number, noise_scales=noise_scales)\n",
    "    print('data expansion')\n",
    "\n",
    "#------------------------data processing---------------------------------#\n",
    "\n",
    "input_shape = (dataset.shape[1],dataset.shape[2])\n",
    "channel = dataset.shape[2]\n",
    "\n",
    "x_number = dataset.shape[0]\n",
    "\n",
    "x = dataset\n",
    "print('x.shape: ',x.shape)\n",
    "y = label\n",
    "print('y.shape: ', y.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_rate, random_state=615)\n",
    "print('x_train.shape: ', x_train.shape)\n",
    "print('x_test.shape: ',x_test.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "\n",
    "x_train_number = x_train.shape[0]\n",
    "x_test_number = x_test.shape[0]\n",
    "print('x_train_number: ',x_train_number)\n",
    "print('x_test_number: ',x_test_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LiftNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 1024, 2)]         0         \n",
      "_________________________________________________________________\n",
      "convinputs (Conv1D)          multiple                  6         \n",
      "_________________________________________________________________\n",
      "predict1_1 (Conv1D)          multiple                  14        \n",
      "_________________________________________________________________\n",
      "predict1_2 (Conv1D)          multiple                  30        \n",
      "_________________________________________________________________\n",
      "update1_1 (Conv1D)           multiple                  62        \n",
      "_________________________________________________________________\n",
      "update1_2 (Conv1D)           multiple                  30        \n",
      "_________________________________________________________________\n",
      "predict2_1 (Conv1D)          multiple                  310       \n",
      "_________________________________________________________________\n",
      "predict2_2 (Conv1D)          multiple                  550       \n",
      "_________________________________________________________________\n",
      "update2_1 (Conv1D)           multiple                  1510      \n",
      "_________________________________________________________________\n",
      "update2_2 (Conv1D)           multiple                  550       \n",
      "_________________________________________________________________\n",
      "predict3_1 (Conv1D)          multiple                  7550      \n",
      "_________________________________________________________________\n",
      "predict3_2 (Conv1D)          multiple                  12750     \n",
      "_________________________________________________________________\n",
      "update3_1 (Conv1D)           multiple                  37550     \n",
      "_________________________________________________________________\n",
      "update3_2 (Conv1D)           multiple                  12750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_41 (Glo multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_41 (Flatten)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "predict (Dense)              multiple                  1506      \n",
      "=================================================================\n",
      "Total params: 75,168\n",
      "Trainable params: 75,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "load model\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------load LiftingNet-------------------------------------------#\n",
    "if whether_use_CWRU_data == 1:\n",
    "    liftnet = create_Standard_LiftNet_CWRU(class_num = class_num, \n",
    "                                       channel = channel, \n",
    "                                       cut_size = cutsize, \n",
    "                                       input_shape = input_shape,\n",
    "                                       lr=lr, \n",
    "                                       momentum = momentum, \n",
    "                                       decay=decay)\n",
    "else:\n",
    "    liftnet = create_Standard_LiftNet(class_num = class_num, \n",
    "                                  channel = channel, \n",
    "                                  circle_num = circle_num, \n",
    "                                  input_shape=input_shape,\n",
    "                                  lr=lr, \n",
    "                                  momentum=momentum, \n",
    "                                  decay=decay)\n",
    "\n",
    "liftnet.load_weights(read_model_name)\n",
    "print('load model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "first predict: \n",
      "WARNING:tensorflow:Entity <bound method Standard_LiftNet.call of <mylib.Standard_LiftNet object at 0x7f8cdbfae0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Standard_LiftNet.call of <mylib.Standard_LiftNet object at 0x7f8cdbfae0b8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Standard_LiftNet.call of <mylib.Standard_LiftNet object at 0x7f8cdbfae0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Standard_LiftNet.call of <mylib.Standard_LiftNet object at 0x7f8cdbfae0b8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "LiftingNet_noise_scale:  2\n",
      "normal result:\n",
      "tp: 140  tn: 9  fp: 63  fn: 555\n",
      "tp/(tp+tn):  0.9395973154362416\n",
      "tp/(tp+fp):  0.6896551724137931\n",
      "inner_ring result:\n",
      "tp: 85  tn: 30  fp: 16  fn: 636\n",
      "tp/(tp+tn):  0.7391304347826086\n",
      "tp/(tp+fp):  0.8415841584158416\n",
      "outer_ring result:\n",
      "tp: 89  tn: 40  fp: 31  fn: 607\n",
      "tp/(tp+tn):  0.689922480620155\n",
      "tp/(tp+fp):  0.7416666666666667\n",
      "roller result:\n",
      "tp: 63  tn: 50  fp: 34  fn: 620\n",
      "tp/(tp+tn):  0.5575221238938053\n",
      "tp/(tp+fp):  0.6494845360824743\n",
      "joint result:\n",
      "tp: 104  tn: 42  fp: 52  fn: 569\n",
      "tp/(tp+tn):  0.7123287671232876\n",
      "tp/(tp+fp):  0.6666666666666666\n",
      "Accuracy: 71.97 % \n",
      "test time: 3.093766212463379s\n",
      "save and delete model\n",
      "------------------------------------------------------------\n",
      "program end\n"
     ]
    }
   ],
   "source": [
    "print('------------------------------------------------------------')\n",
    "print('first predict: ')\n",
    "\n",
    "#test\n",
    "t1 = time.time()\n",
    "pre_y = liftnet.predict(x_test, steps=1)\n",
    "t2 = time.time()\n",
    "#print(pre_y)\n",
    "print('LiftingNet_noise_scale: ', LiftingNet_noise_scale)\n",
    "ml2.evaluate_model(pre_y,y_test)\n",
    "\n",
    "pre_y2 = ml2.pre_to_index(pre_y)\n",
    "\n",
    "# 计算准确率\n",
    "\n",
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if pre_y2[i] == y_test[i]:\n",
    "        cnt1 += 1\n",
    "    else:\n",
    "        cnt2 += 1\n",
    "\n",
    "print(\"Accuracy: %.2f %% \" % (100 * cnt1 / (cnt1 + cnt2)))\n",
    "print('test time: '+str(t2-t1)+'s')\n",
    "del liftnet\n",
    "\n",
    "\n",
    "print('save and delete model')\n",
    "print('------------------------------------------------------------')\n",
    "print('program end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
