{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import plot,savefig\n",
    "from dataset import *\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mylib as ml2\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape :  (832, 1024, 2)\n",
      "label shape :  (832, 1)\n",
      "N: 1024\n",
      "sum_square.shape():  (832, 2)\n",
      "RMS.shape():  (832, 2)\n",
      "data_mean.shape():  (832, 2)\n",
      "data_std.shape():  (832, 2)\n",
      "d_data_mean.shape:  (832, 1024, 2)\n",
      "Variance.shape:  (832, 2)\n",
      "Skewness.shape:  (832, 2)\n",
      "Kurtosis.shape:  (832, 2)\n",
      "SF.shape:  (832, 2)\n",
      "CF.shape:  (832, 2)\n",
      "IF.shape:  (832, 2)\n",
      "MF.shape:  (832, 2)\n",
      "diff1_data.shape:  (832, 1023, 2)\n",
      "diff2_data.shape:  (832, 1022, 2)\n",
      "std_diff1.shape:  (832, 2)\n",
      "std_diff2.shape:  (832, 2)\n",
      "mobility.shape:  (832, 2)\n",
      "complexity.shape:  (832, 2)\n",
      "FC.shape:  (832, 2)\n",
      "MSF.shape:  (832, 2)\n",
      "RMSF.shape:  (832, 2)\n",
      "RVF.shape:  (832, 2)\n",
      "feature_data.shape:  (832, 19, 2)\n",
      "x.shape:  (832, 38)\n",
      "y.shape:  (832,)\n",
      "X_train.shape:  (665, 38)\n",
      "X_test.shape:  (167, 38)\n",
      "y_train.shape:  (665,)\n",
      "y_test.shape:  (167,)\n"
     ]
    }
   ],
   "source": [
    "#------------------------read data----------------------------#\n",
    "cutsize = 256\n",
    "circle_num = 8\n",
    "expansion_data_number = 500\n",
    "noise_scales = 2\n",
    "\"\"\"\n",
    "dataset_file_name = 'dataset_' + str(circle_num) + '_' + str(cutsize) + '.npy'\n",
    "label_file_name = 'label_' + str(circle_num) + '_' + str(cutsize) + '.npy'\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "data_path = '/home/silver-bullet/newpaper/data/dataset/'\n",
    "dataset, label = load_dataset(data_path, circle_num=circle_num, cutsize=cutsize) \n",
    "\"\"\"\n",
    "data_path = '/home/silver-bullet/newpaper/data/CWRUdataset'\n",
    "dataset, label = load_CWRU_data(data_path)\n",
    "\n",
    "\n",
    "if circle_num>=9:\n",
    "    dataset, label = expansion_and_add_noise(dataset,label,exnumber=expansion_data_number, noise_scales=noise_scales)\n",
    "\n",
    "\n",
    "\n",
    "x_number = dataset.shape[0]\n",
    "\n",
    "feature_data = feature_extractor(dataset)\n",
    "print('feature_data.shape: ', feature_data.shape)\n",
    "\n",
    "x = feature_data.reshape(x_number,-1)\n",
    "print('x.shape: ',x.shape)\n",
    "y = label.reshape(x_number,)\n",
    "print('y.shape: ', y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=56)\n",
    "\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('X_test.shape: ',X_test.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans.shape:  (167,)\n",
      "normal result:\n",
      "tp: 42  tn: 0  fp: 0  fn: 125\n",
      "tp/(tp+tn):  1.0\n",
      "tp/(tp+fp):  1.0\n",
      "inner_ring result:\n",
      "tp: 23  tn: 0  fp: 0  fn: 144\n",
      "tp/(tp+tn):  1.0\n",
      "tp/(tp+fp):  1.0\n",
      "outer_ring result:\n",
      "tp: 22  tn: 0  fp: 0  fn: 145\n",
      "tp/(tp+tn):  1.0\n",
      "tp/(tp+fp):  1.0\n",
      "roller result:\n",
      "tp: 30  tn: 0  fp: 0  fn: 137\n",
      "tp/(tp+tn):  1.0\n",
      "tp/(tp+fp):  1.0\n",
      "joint result:\n",
      "tp: 23  tn: 0  fp: 0  fn: 144\n",
      "tp/(tp+tn):  1.0\n",
      "tp/(tp+fp):  1.0\n",
      "Accuracy: 100.00 % \n"
     ]
    }
   ],
   "source": [
    "#---------------------XGBoost----------------------------#\n",
    "\"\"\"\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 5,\n",
    "    'gamma': 0.1,\n",
    "    'max_depth': 8,\n",
    "    'lambda': 2,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'min_child_weight': 3,\n",
    "    'silent': 1,\n",
    "    'eta': 0.1,\n",
    "    'seed': 1000,\n",
    "    'nthread': 4,\n",
    "}\n",
    "\n",
    "plst = params.items()\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "num_rounds = 1000\n",
    "model = xgb.train(plst, dtrain, num_rounds)\n",
    "\"\"\"\n",
    "model = XGBClassifier(learning_rate=0.1,\n",
    "                        n_estimators=500,         # 树的个数--1000棵树建立xgboost\n",
    "                        max_depth=16,               # 树的深度\n",
    "                        min_child_weight = 1,      # 叶子节点最小权重\n",
    "                        gamma=0.1,                  # 惩罚项中叶子结点个数前的参数\n",
    "                        subsample=0.8,             # 随机选择80%样本建立决策树\n",
    "                        colsample_btree=0.8,       # 随机选择80%特征建立决策树\n",
    "                        objective='multi:softmax', # 指定损失函数\n",
    "                        scale_pos_weight=1,        # 解决样本个数不平衡的问题\n",
    "                        )\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "# 对测试集进行预测\n",
    "#dtest = xgb.DMatrix(X_test)\n",
    "#ans = model.predict(dtest)\n",
    "ans = model.predict(X_test)\n",
    "print('ans.shape: ', ans.shape)\n",
    "\n",
    "ml2.evaluate_model2(ans, y_test)\n",
    "\n",
    "# 计算准确率\n",
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if ans[i] == y_test[i]:\n",
    "        cnt1 += 1\n",
    "    else:\n",
    "        cnt2 += 1\n",
    "print(\"Accuracy: %.2f %% \" % (100 * cnt1 / (cnt1 + cnt2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test result:\n",
      "{'train_recall_macro': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_precision_macro': array([1.        , 1.        , 0.99206349, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ]), 'train_precision_macro': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'fit_time': array([1.20431733, 0.89592385, 0.85564017, 0.85766339, 0.86387229,\n",
      "       0.84172654, 0.86490202, 0.84350157, 0.82794499, 0.84486842]), 'score_time': array([0.0054121 , 0.00575161, 0.00665784, 0.00492334, 0.00539732,\n",
      "       0.00521207, 0.00522161, 0.00613785, 0.00447011, 0.00456667]), 'test_recall_macro': array([1.        , 1.        , 0.98148148, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>train_precision_macro</th>\n",
       "      <th>train_recall_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.204317</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.895924</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.855640</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.857663</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.863872</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.841727</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.864902</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.843502</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.827945</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.844868</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_precision_macro  test_recall_macro  \\\n",
       "0  1.204317    0.005412              1.000000           1.000000   \n",
       "1  0.895924    0.005752              1.000000           1.000000   \n",
       "2  0.855640    0.006658              0.992063           0.981481   \n",
       "3  0.857663    0.004923              1.000000           1.000000   \n",
       "4  0.863872    0.005397              1.000000           1.000000   \n",
       "5  0.841727    0.005212              1.000000           1.000000   \n",
       "6  0.864902    0.005222              1.000000           1.000000   \n",
       "7  0.843502    0.006138              1.000000           1.000000   \n",
       "8  0.827945    0.004470              1.000000           1.000000   \n",
       "9  0.844868    0.004567              1.000000           1.000000   \n",
       "\n",
       "   train_precision_macro  train_recall_macro  \n",
       "0                    1.0                 1.0  \n",
       "1                    1.0                 1.0  \n",
       "2                    1.0                 1.0  \n",
       "3                    1.0                 1.0  \n",
       "4                    1.0                 1.0  \n",
       "5                    1.0                 1.0  \n",
       "6                    1.0                 1.0  \n",
       "7                    1.0                 1.0  \n",
       "8                    1.0                 1.0  \n",
       "9                    1.0                 1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------------------K Fold-------------------------------------------#\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "scores = cross_validate(model, X_train, y_train, scoring=scoring,cv=10, return_train_score=True)\n",
    "sorted(scores.keys())\n",
    "print('test result:')\n",
    "print(scores)\n",
    "scores_df = pd.DataFrame(scores)\n",
    "\n",
    "table_header = ['test_recall_macro', 'train_recall_macro','fit_time', 'train_precision_macro','test_precision_macro']\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
