{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import plot,savefig\n",
    "from dataset import *\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import xgboost as xgb\n",
    "import sklearn as sk\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import mylib as ml2\n",
    "from mylib import LiftNet, create_LiftNet, create_Standard_LiftNet, Standard_LiftNet, create_Standard_LiftNet_CWRU\n",
    "\n",
    "from plotly.graph_objs import Scatter,Layout\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape :  (832, 1024, 2)\n",
      "label shape :  (832, 1)\n",
      "(237, 1024, 2)\n",
      "(118, 1024, 2)\n",
      "(117, 1024, 2)\n",
      "(118, 1024, 2)\n",
      "(118, 1024, 2)\n",
      "(118, 1024, 2)\n",
      "(500, 1024, 2)\n",
      "(500, 1)\n",
      "(500, 1024, 2)\n",
      "(500, 1)\n",
      "(500, 1024, 2)\n",
      "(500, 1)\n",
      "(500, 1024, 2)\n",
      "(500, 1)\n",
      "(500, 1024, 2)\n",
      "(500, 1)\n",
      "(500, 1024, 2)\n",
      "(500, 1)\n",
      "(3000, 1024, 2)\n",
      "(3000, 1)\n",
      "data_max_abs_x.shape:  (3000, 1, 2)\n",
      "noise_data.shape:  (3000, 1024, 2)\n",
      "after expansion: \n",
      "dataset shape :  (3832, 1024, 2)\n",
      "label shape :  (3832, 1)\n"
     ]
    }
   ],
   "source": [
    "test_rate = 0.1\n",
    "lr=0.015\n",
    "momentum=0.8\n",
    "decay=0.01\n",
    "validation_split=0.2\n",
    "validation_steps=1\n",
    "epochs = 10000\n",
    "\n",
    "LiftingNet_noise_scale = 0.2\n",
    "train_steps = 800\n",
    "steps_per_epoch=1\n",
    "cutsize = 1024\n",
    "\n",
    "class_num = 6\n",
    "bunch_steps = 100\n",
    "snapshot = 500\n",
    "\n",
    "\n",
    "circle_num =1\n",
    "\n",
    "\n",
    "whether_expansion_data = 1\n",
    "expansion_data_number = 500\n",
    "noise_scales = 0.01\n",
    "\n",
    "\n",
    "model_head_name = '/home/silver-bullet/newpaper/code1216/snapshot/snapshot_CWRU_LiftingNet/Standard_expansion_CWRU_data_LiftingNet_'\n",
    "model_name = model_head_name + str(LiftingNet_noise_scale) + '_data_the_' + str(train_steps) + 'th_snapshot_with_' + str(steps_per_epoch) + '_steps_per_epoch.h5'\n",
    "\n",
    "data_path = '/home/silver-bullet/newpaper/data/CWRUdataset'\n",
    "dataset, label = load_CWRU_data(data_path)\n",
    "\n",
    "if whether_expansion_data == 1:\n",
    "    dataset, label = expansion_and_add_noise(dataset,label,exnumber=expansion_data_number, noise_scales=noise_scales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3832\n",
      "float32\n",
      "dataset shape :  (3832, 1024, 2)\n",
      "label shape :  (3832, 1)\n",
      "p1.shape:  (3832, 2)\n",
      "p2.shape:  (3832, 2)\n",
      "p3.shape:  (3832, 2)\n",
      "p4.shape:  (3832, 2)\n",
      "p5.shape:  (3832, 2)\n",
      "p6.shape:  (3832, 2)\n",
      "p7.shape:  (3832, 2)\n",
      "p8.shape:  (3832, 2)\n",
      "p9.shape:  (3832, 2)\n",
      "(3832, 18)\n"
     ]
    }
   ],
   "source": [
    "x_number = dataset.shape[0]\n",
    "print(x_number)\n",
    "\n",
    "dataset = dataset.astype(np.float32)\n",
    "print(dataset.dtype)\n",
    "print('dataset shape : ',dataset.shape)\n",
    "print('label shape : ', label.shape)\n",
    "\n",
    "input_shape = (dataset.shape[1],dataset.shape[2])\n",
    "channel = dataset.shape[2]\n",
    "\n",
    "select_feature_numbers = 30\n",
    "\n",
    "artificial_feature_data = feature_extractor2(dataset)\n",
    "#artificial_feature_data = artificial_feature_data.reshape(x_number,-1)[:,:select_feature_numbers]\n",
    "artificial_feature_data = artificial_feature_data.reshape(x_number,-1)\n",
    "print(artificial_feature_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LiftNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 1024, 2)]         0         \n",
      "_________________________________________________________________\n",
      "convinputs (Conv1D)          multiple                  6         \n",
      "_________________________________________________________________\n",
      "predict1_1 (Conv1D)          multiple                  14        \n",
      "_________________________________________________________________\n",
      "predict1_2 (Conv1D)          multiple                  30        \n",
      "_________________________________________________________________\n",
      "update1_1 (Conv1D)           multiple                  62        \n",
      "_________________________________________________________________\n",
      "update1_2 (Conv1D)           multiple                  30        \n",
      "_________________________________________________________________\n",
      "predict2_1 (Conv1D)          multiple                  310       \n",
      "_________________________________________________________________\n",
      "predict2_2 (Conv1D)          multiple                  550       \n",
      "_________________________________________________________________\n",
      "update2_1 (Conv1D)           multiple                  1510      \n",
      "_________________________________________________________________\n",
      "update2_2 (Conv1D)           multiple                  550       \n",
      "_________________________________________________________________\n",
      "predict3_1 (Conv1D)          multiple                  7550      \n",
      "_________________________________________________________________\n",
      "predict3_2 (Conv1D)          multiple                  12750     \n",
      "_________________________________________________________________\n",
      "update3_1 (Conv1D)           multiple                  37550     \n",
      "_________________________________________________________________\n",
      "update3_2 (Conv1D)           multiple                  12750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "predict (Dense)              multiple                  1506      \n",
      "=================================================================\n",
      "Total params: 75,168\n",
      "Trainable params: 75,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "load model\n",
      "feature_data.shape:  (3832, 250)\n",
      "(3832, 250)\n",
      "finished feature extract\n",
      "18\n",
      "[9.7246474e-01 5.3550177e-03 4.8917537e-03 3.4779178e-03 2.0618541e-03\n",
      " 1.5749730e-03 1.0080900e-03 6.9159811e-04 5.4476561e-04 4.6660352e-04\n",
      " 4.1068348e-04 3.7169730e-04 3.4897265e-04 2.7277786e-04 2.5804841e-04\n",
      " 2.3544308e-04 2.1009275e-04 1.9792921e-04]\n",
      "(3832, 18)\n"
     ]
    }
   ],
   "source": [
    "liftnet = create_Standard_LiftNet_CWRU(class_num = class_num, channel = channel, cut_size = cutsize, input_shape=input_shape,lr=lr, momentum=momentum, decay=decay)\n",
    "liftnet.load_weights(model_name)\n",
    "print('load model')\n",
    "\n",
    "feature_data = liftnet.feature_extractor(dataset)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    feature_data = feature_data.eval()\n",
    "#feature_data = tf.Session().run(feature_data)\n",
    "#sess = tf.InteractiveSession()\n",
    "#feature_data = feature_data.eval()\n",
    "#print(feature_data)\n",
    "print('feature_data.shape: ', feature_data.shape)\n",
    "feature_data = np.reshape(feature_data,(feature_data.shape[0],feature_data.shape[1]))\n",
    "#feature_data = np.concatenate(dataset,axis=2)\n",
    "print(feature_data.shape)\n",
    "print('finished feature extract')\n",
    "\n",
    "pca_feature_extractor = PCA(n_components=18)\n",
    "pca_feature_extractor.fit(feature_data)\n",
    "pca_feature = pca_feature_extractor.transform(feature_data)\n",
    "print(pca_feature_extractor.n_components_)\n",
    "print(pca_feature_extractor.explained_variance_ratio_)\n",
    "\n",
    "print(pca_feature.shape)\n",
    "\n",
    "x = pca_feature.reshape(x_number,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape:  (3832, 36)\n",
      "y.shape:  (3832,)\n",
      "X_train.shape:  (3448, 36)\n",
      "X_test.shape:  (384, 36)\n",
      "y_train.shape:  (3448,)\n",
      "y_test.shape:  (384,)\n"
     ]
    }
   ],
   "source": [
    "#x = feature_data.reshape(x_number,-1)\n",
    "x = np.concatenate((x,artificial_feature_data),axis=1)\n",
    "print('x.shape: ',x.shape)\n",
    "\n",
    "\n",
    "y = label.reshape(x_number,)\n",
    "print('y.shape: ', y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_rate, random_state=99)\n",
    "\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('X_test.shape: ',X_test.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans.shape:  (384,)\n",
      "normal result:\n",
      "tp: 71  tn: 0  fp: 0  fn: 313\n",
      "tp/(tp+tn):  1.0\n",
      "tp/(tp+fp):  1.0\n",
      "inner_ring result:\n",
      "tp: 48  tn: 0  fp: 1  fn: 335\n",
      "tp/(tp+tn):  1.0\n",
      "tp/(tp+fp):  0.9795918367346939\n",
      "outer_ring result:\n",
      "tp: 67  tn: 0  fp: 0  fn: 317\n",
      "tp/(tp+tn):  1.0\n",
      "tp/(tp+fp):  1.0\n",
      "roller result:\n",
      "tp: 66  tn: 0  fp: 0  fn: 318\n",
      "tp/(tp+tn):  1.0\n",
      "tp/(tp+fp):  1.0\n",
      "joint result:\n",
      "tp: 50  tn: 1  fp: 0  fn: 333\n",
      "tp/(tp+tn):  0.9803921568627451\n",
      "tp/(tp+fp):  1.0\n",
      "Accuracy: 99.48 % \n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(learning_rate=0.1,\n",
    "                        n_estimators=1000,         # 树的个数--1000棵树建立xgboost\n",
    "                        max_depth=8,               # 树的深度\n",
    "                        min_child_weight = 1,      # 叶子节点最小权重\n",
    "                        gamma=0.1,                  # 惩罚项中叶子结点个数前的参数\n",
    "                        subsample=0.8,             # 随机选择80%样本建立决策树\n",
    "                        colsample_btree=0.8,       # 随机选择80%特征建立决策树\n",
    "                        objective='multi:softmax', # 指定损失函数\n",
    "                        scale_pos_weight=1,        # 解决样本个数不平衡的问题\n",
    "                        )\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "# 对测试集进行预测\n",
    "#dtest = xgb.DMatrix(X_test)\n",
    "#ans = model.predict(dtest)\n",
    "ans = model.predict(X_test)\n",
    "print('ans.shape: ', ans.shape)\n",
    "\n",
    "\n",
    "ml2.evaluate_model2(ans, y_test)\n",
    "\n",
    "# 计算准确率\n",
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if ans[i] == y_test[i]:\n",
    "        cnt1 += 1\n",
    "    else:\n",
    "        cnt2 += 1\n",
    "print(\"Accuracy: %.2f %% \" % (100 * cnt1 / (cnt1 + cnt2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test result:\n",
      "{'train_precision_macro': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_precision_macro': array([0.99707602, 1.        , 0.99404002, 1.        , 1.        ,\n",
      "       1.        , 0.99404762, 0.99712644, 0.99712644, 0.99712644]), 'fit_time': array([13.38010383, 13.28495574, 12.99477887, 13.18203425, 13.32385278,\n",
      "       13.51523328, 13.08314133, 13.23658061, 13.24838877, 13.800699  ]), 'test_recall_macro': array([0.99691358, 1.        , 0.99388328, 1.        , 1.        ,\n",
      "       1.        , 0.99404572, 0.99691358, 0.99685535, 0.99685535]), 'score_time': array([0.05414057, 0.05735016, 0.04951906, 0.05421567, 0.0493238 ,\n",
      "       0.04933429, 0.05040956, 0.05186629, 0.04876661, 0.04947686]), 'train_recall_macro': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>train_precision_macro</th>\n",
       "      <th>train_recall_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.380104</td>\n",
       "      <td>0.054141</td>\n",
       "      <td>0.997076</td>\n",
       "      <td>0.996914</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.284956</td>\n",
       "      <td>0.057350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.994779</td>\n",
       "      <td>0.049519</td>\n",
       "      <td>0.994040</td>\n",
       "      <td>0.993883</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.182034</td>\n",
       "      <td>0.054216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.323853</td>\n",
       "      <td>0.049324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.515233</td>\n",
       "      <td>0.049334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.083141</td>\n",
       "      <td>0.050410</td>\n",
       "      <td>0.994048</td>\n",
       "      <td>0.994046</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.236581</td>\n",
       "      <td>0.051866</td>\n",
       "      <td>0.997126</td>\n",
       "      <td>0.996914</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.248389</td>\n",
       "      <td>0.048767</td>\n",
       "      <td>0.997126</td>\n",
       "      <td>0.996855</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.800699</td>\n",
       "      <td>0.049477</td>\n",
       "      <td>0.997126</td>\n",
       "      <td>0.996855</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_precision_macro  test_recall_macro  \\\n",
       "0  13.380104    0.054141              0.997076           0.996914   \n",
       "1  13.284956    0.057350              1.000000           1.000000   \n",
       "2  12.994779    0.049519              0.994040           0.993883   \n",
       "3  13.182034    0.054216              1.000000           1.000000   \n",
       "4  13.323853    0.049324              1.000000           1.000000   \n",
       "5  13.515233    0.049334              1.000000           1.000000   \n",
       "6  13.083141    0.050410              0.994048           0.994046   \n",
       "7  13.236581    0.051866              0.997126           0.996914   \n",
       "8  13.248389    0.048767              0.997126           0.996855   \n",
       "9  13.800699    0.049477              0.997126           0.996855   \n",
       "\n",
       "   train_precision_macro  train_recall_macro  \n",
       "0                    1.0                 1.0  \n",
       "1                    1.0                 1.0  \n",
       "2                    1.0                 1.0  \n",
       "3                    1.0                 1.0  \n",
       "4                    1.0                 1.0  \n",
       "5                    1.0                 1.0  \n",
       "6                    1.0                 1.0  \n",
       "7                    1.0                 1.0  \n",
       "8                    1.0                 1.0  \n",
       "9                    1.0                 1.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------------------K Fold-------------------------------------------#\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "scores = cross_validate(model, X_train, y_train, scoring=scoring,cv=10, return_train_score=True)\n",
    "sorted(scores.keys())\n",
    "print('test result:')\n",
    "print(scores)\n",
    "scores_df = pd.DataFrame(scores)\n",
    "\n",
    "table_header = ['test_recall_macro', 'train_recall_macro','fit_time', 'train_precision_macro','test_precision_macro']\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
